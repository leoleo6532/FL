{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets ,models,transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "#Determine if there is a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_train=\"./train\"\n",
    "PATH_val=\"./val\"\n",
    "PATH_test=\"./test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "TRAIN =Path(PATH_train)\n",
    "VALID = Path(PATH_val)\n",
    "TEST=Path(PATH_test)\n",
    "print(TRAIN)\n",
    "print(VALID)\n",
    "print(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "# learning rate\n",
    "LR = 0.01  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "train_transforms = transforms.Compose([transforms.Resize((50,50)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize((50,50)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((50,50)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the training and test datasets\n",
    "train_data = datasets.ImageFolder(TRAIN, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(VALID,transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(TEST, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sick': 0, 'unsick': 1}\n",
      "{'sick': 0, 'unsick': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_data.class_to_idx)\n",
    "print(valid_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,  num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 50, 50]), torch.Size([1]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images,labels=next(iter(train_loader))\n",
    "images.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "classes = ['sick','unsick']\n",
    "mean , std = torch.tensor([0.485, 0.456, 0.406]),torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def denormalize(image):\n",
    "  image = transforms.Normalize(-mean/std,1/std)(image) #denormalize\n",
    "  image = image.permute(1,2,0) #Changing from 3x224x224 to 224x224x3\n",
    "  image = torch.clamp(image,0,1)\n",
    "  return image\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = denormalize(img) \n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo6532/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f34b2497f53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    " # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(\"{} \".format( classes[labels[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN Model\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0) #output_shape=(16,220,220) 48\n",
    "        #(224-5+1)/1 #(weigh-kernel+1)/stride 無條件進位\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) #output_shape=(16,110,110) #(220/2) 16 24 24\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0) #output_shape=(32,106,106) 20 20\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=1) #output_shape=(32,53,53) 10 10\n",
    "        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, stride=1, padding=0) #output_shape=(16,51,51) 10 10\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=1) #output_shape=(16,25,25) 5 5\n",
    "        self.cnn4 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=1, stride=1, padding=0) #output_shape=(8,23,23) 5 5\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2) #output_shape=(8,11,11) 8 5 5\n",
    "        # Fully connected 1 ,#input_shape=(8*12*12)\n",
    "        self.fc1 = nn.Linear(8 * 11 * 11, 512) \n",
    "        self.relu5 = nn.ReLU() # activation\n",
    "        self.fc2 = nn.Linear(512, 2) \n",
    "        self.output = nn.Softmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x) # Convolution 1\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)# Max pool 1\n",
    "        out = self.cnn2(out) # Convolution 2\n",
    "        out = self.relu2(out) \n",
    "        out = self.maxpool2(out) # Max pool 2\n",
    "        out = self.cnn3(out) # Convolution 3\n",
    "        out = self.relu3(out)\n",
    "        out = self.maxpool3(out) # Max pool 3\n",
    "        out = self.cnn4(out) # Convolution 4\n",
    "        out = self.relu4(out)\n",
    "        out = self.maxpool4(out) # Max pool 4\n",
    "        out = out.view(out.size(0), -1) # last CNN faltten con. Linear NN\n",
    "        out = self.fc1(out) # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        out = self.output(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "              ReLU-2           [-1, 16, 48, 48]               0\n",
      "         MaxPool2d-3           [-1, 16, 24, 24]               0\n",
      "            Conv2d-4           [-1, 32, 22, 22]           4,640\n",
      "              ReLU-5           [-1, 32, 22, 22]               0\n",
      "         MaxPool2d-6           [-1, 32, 22, 22]               0\n",
      "            Conv2d-7           [-1, 16, 22, 22]             528\n",
      "              ReLU-8           [-1, 16, 22, 22]               0\n",
      "         MaxPool2d-9           [-1, 16, 22, 22]               0\n",
      "           Conv2d-10            [-1, 8, 22, 22]             136\n",
      "             ReLU-11            [-1, 8, 22, 22]               0\n",
      "        MaxPool2d-12            [-1, 8, 11, 11]               0\n",
      "           Linear-13                  [-1, 512]         496,128\n",
      "           Linear-14                    [-1, 2]           1,026\n",
      "          Softmax-15                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 502,906\n",
      "Trainable params: 502,906\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 1.23\n",
      "Params size (MB): 1.92\n",
      "Estimated Total Size (MB): 3.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN_Model()\n",
    "from torchsummary import summary\n",
    "summary(model.cuda(), (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.1, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "criterion = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c6621a0bdc4e68a32e9c9d62185e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5187.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d735530a0e4c4cb2fbc6877829aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1297.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTraining Loss: 0.476243 \tValidation Loss: 0.485968\n",
      "Validation loss decreased (inf --> 0.485968).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "# number of epochs to train the model\n",
    "n_epochs = 1\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "#train_losses,valid_losses=[],[]\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    print('running epoch: {}'.format(epoch))\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in tqdm(valid_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    #train_losses.append(train_loss/len(train_loader.dataset))\n",
    "    #valid_losses.append(valid_loss.item()/len(valid_loader.dataset)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_CNN.pth')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}'.format(test_loss))\n",
    "\n",
    "    print('Test Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.487121\n",
      "Test Accuracy: 82% (1340/1622)\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "model.cuda()\n",
    "test(test_loader, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
